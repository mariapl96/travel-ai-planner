"""
Sistema RAG (Retrieval Augmented Generation)
Gestiona la base de conocimiento y b√∫squeda de informaci√≥n relevante
"""

import os
from typing import List
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from config import RAG_CONFIG, EMBEDDING_CONFIG


class RAGSystem:
    """
    Sistema RAG para recuperar informaci√≥n relevante de la base de conocimiento
    """
    
    def __init__(self):
        """
        Inicializa el sistema RAG
        """
        self.knowledge_base_path = RAG_CONFIG["knowledge_base_path"]
        self.chunk_size = RAG_CONFIG["chunk_size"]
        self.chunk_overlap = RAG_CONFIG["chunk_overlap"]
        self.top_k = RAG_CONFIG["top_k"]
        
        # Inicializar modelo de embeddings
        print("Cargando modelo de embeddings...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name=EMBEDDING_CONFIG["model_name"],
            model_kwargs={'device': EMBEDDING_CONFIG["device"]}
        )
        
        # Cargar o crear vector store
        self.vector_store = None
        self.load_or_create_vector_store()
        
        print("‚úÖSistema RAG inicializado correctamente")
    
    
    def load_documents(self) -> List[Document]:
        """
        Carga todos los documentos de la base de conocimiento
        
        Returns:
            List[Document]: Lista de documentos cargados
        """
        documents = []
        
        # Verificar que existe la carpeta
        if not os.path.exists(self.knowledge_base_path):
            raise FileNotFoundError(f"No se encuentra la carpeta: {self.knowledge_base_path}")
        
        # Leer todos los archivos .txt de la carpeta
        for filename in os.listdir(self.knowledge_base_path):
            if filename.endswith('.txt'):
                filepath = os.path.join(self.knowledge_base_path, filename)
                
                try:
                    with open(filepath, 'r', encoding='utf-8') as file:
                        content = file.read()
                        
                        # Crear documento con metadata
                        doc = Document(
                            page_content=content,
                            metadata={
                                "source": filename,
                                "destination": filename.replace('.txt', '').title()
                            }
                        )
                        documents.append(doc)
                        print(f"  ‚úì Cargado: {filename}")
                        
                except Exception as e:
                    print(f"  ‚úó Error cargando {filename}: {e}")
        
        print(f"üìÑ Total documentos cargados: {len(documents)}")
        return documents
    
    
    def split_documents(self, documents: List[Document]) -> List[Document]:
        """
        Divide documentos en fragmentos m√°s peque√±os (chunks)
        
        Args:
            documents: Lista de documentos
            
        Returns:
            List[Document]: Documentos divididos en chunks
        """
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
        
        chunks = text_splitter.split_documents(documents)
        print(f"Documentos divididos en {len(chunks)} fragmentos")
        
        return chunks
    
    
    def create_vector_store(self, chunks: List[Document]):
        """
        Crea el vector store (base de datos vectorial) a partir de los chunks
        
        Args:
            chunks: Lista de fragmentos de documentos
        """
        print("Creando vector store (puede tardar un poco)...")
        
        self.vector_store = FAISS.from_documents(
            documents=chunks,
            embedding=self.embeddings
        )
        
        print("‚úÖVector store creado correctamente")
    
    
    def load_or_create_vector_store(self):
        """
        Carga vector store existente o crea uno nuevo
        """
        vector_store_path = "data/faiss_index"
        
        # Intentar cargar vector store existente
        if os.path.exists(vector_store_path):
            try:
                print("üìÇ Cargando vector store existente...")
                self.vector_store = FAISS.load_local(
                    vector_store_path, 
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                print("‚úÖVector store cargado desde disco")
                return
            except Exception as e:
                print(f"‚ö†Ô∏èError cargando vector store: {e}")
                print("Creando nuevo vector store...")
        
        # Si no existe o falla la carga, crear nuevo
        documents = self.load_documents()
        
        if not documents:
            raise ValueError("No se encontraron documentos en la base de conocimiento")
        
        chunks = self.split_documents(documents)
        self.create_vector_store(chunks)
        
        # Guardar vector store para futuras ejecuciones
        try:
            os.makedirs("data", exist_ok=True)
            self.vector_store.save_local(vector_store_path)
            print("Vector store guardado en disco")
        except Exception as e:
            print(f"‚ö†Ô∏èNo se pudo guardar vector store: {e}")
    
    
    def search(self, query: str, k: int = None) -> str:
        """
        Busca informaci√≥n relevante en la base de conocimiento
        
        Args:
            query: Consulta de b√∫squeda
            k: N√∫mero de resultados a devolver (usa self.top_k por defecto)
            
        Returns:
            str: Informaci√≥n relevante formateada
        """
        if not self.vector_store:
            return "‚ö†Ô∏èSistema RAG no inicializado correctamente"
        
        k = k or self.top_k
        
        try:
            # B√∫squeda de similitud
            results = self.vector_store.similarity_search(query, k=k)
            
            if not results:
                return "No se encontr√≥ informaci√≥n relevante en la base de conocimiento."
            
            # Formatear resultados
            context = "**Informaci√≥n relevante de la base de conocimiento:**\n\n"
            
            for i, doc in enumerate(results, 1):
                destination = doc.metadata.get("destination", "Desconocido")
                content = doc.page_content.strip()
                
                context += f"**[Fuente: {destination}]**\n{content}\n\n"
                
                # Separador entre fragmentos
                if i < len(results):
                    context += "---\n\n"
            
            return context
            
        except Exception as e:
            return f"‚ö†Ô∏èError en b√∫squeda RAG: {str(e)}"
    
    
    def search_by_destination(self, destination: str) -> str:
        """
        Busca informaci√≥n espec√≠fica de un destino
        
        Args:
            destination: Nombre del destino
            
        Returns:
            str: Informaci√≥n del destino
        """
        query = f"informaci√≥n completa sobre {destination} atracciones gastronom√≠a transporte presupuesto"
        return self.search(query, k=5)
    
    
    def get_destination_summary(self, destination: str) -> str:
        """
        Obtiene un resumen del destino
        
        Args:
            destination: Nombre del destino
            
        Returns:
            str: Resumen del destino
        """
        # Buscar archivo espec√≠fico del destino
        filename = f"{destination.lower()}.txt"
        filepath = os.path.join(self.knowledge_base_path, filename)
        
        if os.path.exists(filepath):
            try:
                with open(filepath, 'r', encoding='utf-8') as file:
                    content = file.read()
                    # Devolver primeros 1000 caracteres como resumen
                    return content[:1000] + "..." if len(content) > 1000 else content
            except Exception as e:
                return f"Error leyendo informaci√≥n de {destination}: {e}"
        else:
            # Si no existe archivo espec√≠fico, usar b√∫squeda sem√°ntica
            return self.search_by_destination(destination)


# Funci√≥n auxiliar para testing
if __name__ == "__main__":
    print("Testing RAG System...\n")
    
    # Inicializar sistema
    rag = RAGSystem()
    
    # Test 1: B√∫squeda general
    print("\n" + "="*50)
    print("TEST 1: B√∫squeda general sobre Par√≠s")
    print("="*50)
    results = rag.search("mejores restaurantes y comida en Par√≠s")
    print(results)
    
    # Test 2: B√∫squeda por destino
    print("\n" + "="*50)
    print("TEST 2: Informaci√≥n completa de Barcelona")
    print("="*50)
    results = rag.search_by_destination("Barcelona")
    print(results)
    
    print("\n‚úÖTests completados")